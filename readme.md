# Projeto Iris - Assistente JurÃ­dico com MemÃ³ria TemporÃ¡ria

Este projeto Ã© um assistente jurÃ­dico baseado em IA, construÃ­do com **FastAPI** no backend e um site simples com HTML/CSS/JS no frontend. A IA responde com base no modelo da **OpenAI** e agora tem suporte a **memÃ³ria temporÃ¡ria** de conversa, igual ao ChatGPT.

> A memÃ³ria dura apenas enquanto o usuÃ¡rio mantÃ©m o site aberto. Se atualizar (F5), a conversa reinicia.

---

## ðŸ”§ Estrutura de arquivos e explicaÃ§Ãµes detalhadas

```
IRIS_PROJECT/
â”œâ”€â”€ .env                          # Chave da API da OpenAI
â”œâ”€â”€ assistente/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ main.py               # Backend FastAPI que recebe e responde perguntas
â”‚   â”‚   â””â”€â”€ documentos.py         # LÃª os arquivos da pasta 'dados/' para gerar contexto
â”‚   â””â”€â”€ public/
â”‚       â”œâ”€â”€ index.html            # Interface do chat
â”‚       â”œâ”€â”€ app.js                # LÃ³gica do chat com memÃ³ria temporÃ¡ria
â”‚       â””â”€â”€ style.css             # Estilos visuais do chat
â”œâ”€â”€ dados/                        # Pasta onde ficam os arquivos de referÃªncia (.pdf, .txt)
â”‚   â””â”€â”€ exemplo.txt / guia.pdf
```

---

### ðŸ“„ `.env`

ContÃ©m a chave da API da OpenAI:
```
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
```
Essa chave Ã© usada para autenticar chamadas Ã  IA.

---

### ðŸ“„ `main.py`

Arquivo principal do backend (FastAPI). Ele:
- ExpÃµe a rota `/api/consulta` que recebe perguntas do frontend
- Recebe uma lista de mensagens (`messages[]`) simulando uma conversa
- Chama a OpenAI com esse histÃ³rico e retorna a resposta
- Serve o site (HTML/CSS/JS) via `StaticFiles`

**Exemplo de mensagens enviadas:**
```json
[
  { "role": "system", "content": "VocÃª Ã© um assistente jurÃ­dico..." },
  { "role": "user", "content": "Oi!" },
  { "role": "assistant", "content": "OlÃ¡! Como posso ajudar?" },
  { "role": "user", "content": "Qual o prazo para registro de nascimento?" }
]
```

---

### ðŸ“„ `documentos.py`

Arquivo que lÃª automaticamente todos os documentos da pasta `dados/`, incluindo:
- `.pdf` (usando PyMuPDF)
- `.txt`

Ele retorna um texto longo com o conteÃºdo desses arquivos. Esse texto pode ser usado para alimentar o prompt da IA futuramente.

---

### ðŸ“„ `index.html`

Interface bÃ¡sica do chat:
- Uma caixa de entrada (textarea)
- BotÃ£o para enviar a mensagem
- Ãrea de exibiÃ§Ã£o das mensagens do usuÃ¡rio e da IA

---

### ðŸ“„ `app.js`

ContÃ©m toda a lÃ³gica do chat no navegador:
- Armazena um array chamado `chatHistory` com todas as mensagens
- A cada envio, envia **todo o histÃ³rico** para o backend
- Adiciona a resposta da IA ao histÃ³rico para manter a conversa
- Se o site for recarregado, esse histÃ³rico se perde (memÃ³ria temporÃ¡ria)

---

### ðŸ“„ `style.css`

Define a aparÃªncia do chat:
- Fundo escuro (modo noturno)
- Diferencia mensagem do usuÃ¡rio e da IA por cor e alinhamento
- Estiliza textarea, botÃ£o e espaÃ§amento

---

### ðŸ“„ Pasta `dados/`

ContÃ©m arquivos usados como base para as respostas do assistente.
- Ex: `guia_cartorio.pdf`, `documentos_exigidos.txt`
- Esses arquivos sÃ£o lidos automaticamente (via `documentos.py`)

---

## ðŸŒ Como rodar

1. Instale as dependÃªncias:
```bash
pip install fastapi uvicorn openai python-dotenv PyMuPDF
```

2. Rode o backend:
```bash
uvicorn assistente.backend.main:app --reload
```

3. Acesse o site:
```
http://localhost:8000
```

---

Se quiser, vocÃª pode evoluir para:

- **MemÃ³ria persistente por usuÃ¡rio** (em banco de dados)
- **Busca inteligente nos arquivos com embeddings (RAG)**
- **Painel administrativo para gerenciar os dados**

> Para isso, continue usando o `documentos.py` e ampliando o fluxo no `main.py`.

